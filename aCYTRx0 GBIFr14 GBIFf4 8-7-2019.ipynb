{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Canyon Treefrog Occurrence Records Summary\n",
    "This notebook is a tool for exploring data sets requested from GBIF (and eventually other sources), and mostly for developing criteria for filtering records (filter sets).  When the entire notebook is run, it retrieves records according to the filter sets specified and saves the results (records and some summary tables) in an sqlite database.  Some information is pulled from the parameters.sqlite database that is saved in this repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sqlite3\n",
    "import pprint\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import geopandas as gpd\n",
    "pd.set_option('display.width', 600)\n",
    "pd.set_option('display.max_colwidth', 60)\n",
    "pd.set_option('display.max_rows', 150)\n",
    "from IPython.display import Image\n",
    "from pygbif import occurrences\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime\n",
    "t1 = datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config file\n",
    "Some of the scripts below pull variables from a config file.  This is in order to reduce redundancy and also facilitates running scripts outside of jupyter notebooks.  However, variables need to be able to be set in notebooks too, so the cell below deletes and then rewrites the config file according to what you want for running this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook run 2019-08-08 18:25:42.048210\n"
     ]
    }
   ],
   "source": [
    "# Set variables in the following text string, not variable assignment below.\n",
    "text = \"\"\"#NOTE! this is overwritten by some notebooks, so update everywhere, if adding lines.\n",
    "sp_id = 'acytrx0'\n",
    "summary_name = 'canyon'\n",
    "gbif_req_id = 'GBIFr14'\n",
    "gbif_filter_id = 'GBIFf4'\n",
    "workDir = 'T:/Occurrence_Records/'\n",
    "codeDir = 'T:/Scripts/occurrence-record-wrangler/'\n",
    "inDir = workDir + 'Inputs/'\n",
    "outDir = workDir + 'Outputs/'\n",
    "default_coordUncertainty = 500\n",
    "SRID_dict = {'WGS84': 4326, 'AlbersNAD83': 102008} # Used in file names for output.\n",
    "spdb = outDir + sp_id + gbif_req_id + gbif_filter_id + '.sqlite'\n",
    "\"\"\"\n",
    "f = open('config.py', 'w')\n",
    "f.write(text)\n",
    "f.close()\n",
    "\n",
    "import config\n",
    "species_id = config.sp_id\n",
    "summary_name = config.summary_name\n",
    "request_id = config.gbif_req_id\n",
    "filter_id = config.gbif_filter_id\n",
    "inDir = config.inDir\n",
    "outDir = config.outDir\n",
    "print(\"Notebook run \" + str(t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "connjup = sqlite3.connect(config.codeDir + 'parameters.sqlite')\n",
    "cursorjup = connjup.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Species Concept\n",
    "Display information on the species from the parameters.sqlite database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bcb_id': None,\n",
      " 'breeding_months': '',\n",
      " 'common_name': 'canyon treefrog',\n",
      " 'detection_distance_meters': 0,\n",
      " 'end_year': '',\n",
      " 'error_tolerance': 20,\n",
      " 'fws_id': 'Hyla arenicolor',\n",
      " 'gap_id': 'acytrx',\n",
      " 'gbif_id': '2427572',\n",
      " 'geometry': '',\n",
      " 'itis_tsn': '173510',\n",
      " 'migratory': '',\n",
      " 'notes': '',\n",
      " 'pad': 1,\n",
      " 'scientific_name': 'Hyla arenicolor',\n",
      " 'species_id': 'acytrx0',\n",
      " 'start_year': '',\n",
      " 'wintering_months': ''}\n"
     ]
    }
   ],
   "source": [
    "vals = cursorjup.execute(\"SELECT * FROM species_concepts WHERE species_id = '{0}';\".format(species_id)).fetchall()[0]\n",
    "cols = [x[1] for x in cursorjup.execute(\"PRAGMA table_info('species_concepts')\").fetchall()]\n",
    "pprint.pprint(dict(zip(cols, vals)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filters\n",
    "Display the parameters of the request filter set.  These are deployed during the step where records are retrieved from the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE REQUEST FILTER SET\n",
      "request_id                                                          GBIFr14\n",
      "source                                                                 GBIF\n",
      "lat_range                                                             27,41\n",
      "lon_range                                                           -91,-75\n",
      "years_range                                                       2000,2002\n",
      "months_range                                                           1,12\n",
      "geoissue                                                              False\n",
      "coordinate                                                             True\n",
      "continent                                                              None\n",
      "creator                                                             N. Tarr\n",
      "notes           For evaluating 2001 GAP range maps.  Are the years correct?\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_sql_query(sql=\"SELECT * FROM gbif_requests WHERE request_id = '{0}'\".format(request_id), con=connjup)\n",
    "print(\"THE REQUEST FILTER SET\")\n",
    "print(df1.loc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the parameters of the post-request filter set.  These are deployed after the records are retrieved from the API, but before they are stored in the occurrence record sqlite database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE POST REQUEST FILTER SET\n",
      "filter_id                                                                          GBIFf4\n",
      "dataset                                                                              GBIF\n",
      "collection_codes_omit                                                                None\n",
      "institutions_omit                                                                    None\n",
      "has_coordinate_uncertainty                                                              0\n",
      "max_coordinate_uncertainty                                                           5000\n",
      "bases_omit                                            PRESERVED_SPECIMEN, FOSSIL_SPECIMEN\n",
      "protocols_omit                                                                       None\n",
      "sampling_protocols_omit                                                              None\n",
      "issues_omit                   GEODETIC_DATUM_INVALID, INDIVIDUAL_COUNT_INVALID, MULTIM...\n",
      "creator                                                                           N. Tarr\n",
      "notes                                                                                None\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_sql_query(sql=\"SELECT * FROM gbif_filters WHERE filter_id = '{0}'\".format(filter_id), con=connjup)\n",
    "print(\"THE POST REQUEST FILTER SET\")\n",
    "print(df2.loc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter set justification\n",
    "default_coord_uncertainty: I chose 500 because eBird data is included, and traveling counts may be included as a point coordinate.\n",
    "\n",
    "years_range: I wanted current records, but not so many that runtime is slow.\n",
    "\n",
    "months_range: I wanted to minimize the inclusion of migrating birds.\n",
    "\n",
    "geoissue: Setting to False ensures exclusion of records with noted geoissues.\n",
    "\n",
    "coordinate: Setting to True ensures that records are only kept if they have a coordinate.\n",
    "\n",
    "continent: Setting to \"North America\" actually filters out lots of records, possibly just because the field is blank for those records.  Set to \"None\" for that reason.\n",
    "\n",
    "collection_codes_omit: --\n",
    "\n",
    "institutions_omit: --\n",
    "\n",
    "has_coordinate_uncertainty: Did not require this because it would omit ebird data.\n",
    "\n",
    "max_coordinate_uncertainty: No real logic behind the choice.\n",
    "\n",
    "bases_omit: Only interested in records of living animals, so omitted preserved specimens and fossils\n",
    "\n",
    "protocols_omit: --\n",
    "\n",
    "sampling_protocols_omit: --\n",
    "\n",
    "issues_omit: Invalid datums create spatial error in point locations.  Invalid counts seem like a red flag for data quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading https://www.sciencebase.gov/catalog/file/get/59f5e29fe4b063d5d307dfab?f=__disk__95%2F4e%2F9d%2F954e9d28eb598bb17e4bc8c803f7b748a2e650bc to T:/Occurrence_Records/Inputs/aCYTRx_CONUS_Range_2001v1.zip\n",
      "downloading https://www.sciencebase.gov/catalog/file/get/59f5e29fe4b063d5d307dfab?f=__disk__ec%2Fe7%2Fe4%2Fece7e4d55e30514670a82b61b3728f042b5ae541 to T:/Occurrence_Records/Inputs/aCYTRx_CONUS_Range_2001v1.xml\n",
      "T:/Occurrence_Records/Outputs/acytrx0GBIFr14GBIFf4.sqlite\n",
      "\n",
      "255 records exist with the request parameters\n",
      "\n",
      "Records saved in T:/Occurrence_Records/Outputs/acytrx0GBIFr14GBIFf4.sqlite\n"
     ]
    }
   ],
   "source": [
    "# Run a script that retrieves and filters\n",
    "%run \"retrieve_occurrences.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many records made it through the filters?\n",
    "This is the number that was actually saved in the occurrence record sqlite database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 records\n"
     ]
    }
   ],
   "source": [
    "conn_occ= sqlite3.connect(config.spdb)\n",
    "curs_occ = conn_occ.cursor()\n",
    "record_count = curs_occ.execute(\"SELECT COUNT(occ_id) FROM occurrences WHERE species_id = '{0}'\".format(species_id)).fetchone()\n",
    "print(str(record_count[0]) + \" records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Were there duplicate records?\n",
    "needs to be addressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 records were duplicates based on xy coordinate and date-time\n"
     ]
    }
   ],
   "source": [
    "dups0 = curs_occ.execute(\"SELECT COUNT(occ_id) FROM occurrences GROUP BY geom_xy4326, occurrenceDate;\").fetchall()\n",
    "dups1 = [x[0] for x in dups0]\n",
    "dups2 = [x for x in dups1 if x > 1]\n",
    "print(str(len(dups2)) + ' records were duplicates based on xy coordinate and date-time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Institutions\n",
    "#### Pre-filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UCM (2)\n",
      "68 (239)\n",
      "MSB (1)\n",
      "1849 (2)\n",
      "http://biocol.org/urn:lsid:biocol.org:col:34852 (4)\n",
      "UTEP (4)\n",
      "iNaturalist (2)\n",
      "2027 (1)\n"
     ]
    }
   ],
   "source": [
    "institutions = curs_occ.execute(\"SELECT value, count FROM post_request_value_counts WHERE attribute = 'institutions';\").fetchall()\n",
    "for x in institutions:\n",
    "    print(x[0] + \" ({0})\".format(x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Post-filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iNaturalist\n"
     ]
    }
   ],
   "source": [
    "institutions = curs_occ.execute(\"SELECT vals FROM record_attributes WHERE field = 'institutions' AND step = 'filter';\").fetchone()[0]\n",
    "institutions = institutions.replace('[', '').strip().replace(']', '').replace(\"'\", \"\")\n",
    "institutions = institutions.split(',')\n",
    "for ins in institutions:\n",
    "    print(ins.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collections\n",
    "#### Pre-filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amphibian and reptile specimens (7)\n",
      "LE-UBIPRO (239)\n",
      "CIB-UAEH (2)\n",
      "Herpetology (4)\n",
      "Observations (2)\n",
      "ENCB (1)\n"
     ]
    }
   ],
   "source": [
    "collections = curs_occ.execute(\"SELECT value, count FROM post_request_value_counts WHERE attribute = 'collections';\").fetchall()\n",
    "for x in collections:\n",
    "    print(x[0] + \" ({0})\".format(x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Post-filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations\n"
     ]
    }
   ],
   "source": [
    "collections = curs_occ.execute(\"SELECT vals FROM record_attributes WHERE field = 'collections' AND step = 'filter';\").fetchone()[0]\n",
    "collections = collections.replace('[', '').strip().replace(']', '').replace(\"'\", \"\")\n",
    "collections = collections.split(',')\n",
    "for colls in collections:\n",
    "    print(colls.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bases\n",
    "#### Pre-filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRESERVED_SPECIMEN (253)\n",
      "HUMAN_OBSERVATION (2)\n"
     ]
    }
   ],
   "source": [
    "bases = curs_occ.execute(\"SELECT value, count FROM post_request_value_counts WHERE attribute = 'bases';\").fetchall()\n",
    "for x in bases:\n",
    "    print(x[0] + \" ({0})\".format(x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Post-filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HUMAN_OBSERVATION\n"
     ]
    }
   ],
   "source": [
    "bases = curs_occ.execute(\"SELECT vals FROM record_attributes WHERE field = 'bases' AND step = 'filter';\").fetchone()[0]\n",
    "bases = bases.replace('[', '').strip().replace(']', '').replace(\"'\", \"\")\n",
    "bases = bases.split(\",\")\n",
    "for bas in bases:\n",
    "    print(bas.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Protocols\n",
    "#### Pre-filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DWC_ARCHIVE (255)\n"
     ]
    }
   ],
   "source": [
    "protocols = curs_occ.execute(\"SELECT value, count FROM post_request_value_counts WHERE attribute = 'protocols';\").fetchall()\n",
    "for x in protocols:\n",
    "    print(x[0] + \" ({0})\".format(x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Post-filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DWC_ARCHIVE\n"
     ]
    }
   ],
   "source": [
    "protos = curs_occ.execute(\"SELECT vals FROM record_attributes WHERE field = 'protocols' AND step = 'filter';\").fetchall()[0]\n",
    "for pro in protos:\n",
    "    pro = pro.replace('[', '').strip().replace(']', '').replace(\"'\", \"\")\n",
    "    print(pro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Issues\n",
    "#### Pre-filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COORDINATE_ROUNDED (253)\n",
      "GEODETIC_DATUM_ASSUMED_WGS84 (250)\n",
      "GEODETIC_DATUM_INVALID (243)\n",
      "TAXON_MATCH_HIGHERRANK (243)\n",
      "ELEVATION_MIN_MAX_SWAPPED (3)\n"
     ]
    }
   ],
   "source": [
    "issues = curs_occ.execute(\"SELECT value, count FROM post_request_value_counts WHERE attribute = 'issues';\").fetchall()\n",
    "for x in issues:\n",
    "    print(x[0] + \" ({0})\".format(x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Post-filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COORDINATE_ROUNDED\n",
      "GEODETIC_DATUM_ASSUMED_WGS84\n"
     ]
    }
   ],
   "source": [
    "issues = curs_occ.execute(\"SELECT vals FROM record_attributes WHERE field = 'issues' AND step = 'filter';\").fetchone()[0]\n",
    "issues = issues.replace('[', '').strip().replace(']', '').replace(\"'\", \"\")\n",
    "issues = issues.split(',')\n",
    "for iss in issues:\n",
    "    print(iss.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptions of filtered records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mpl_toolkits.basemap'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-df1df33177ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"{1} ({0})\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myears\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcommon_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mfunctions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMapShapefilePolygons\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap_these\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmap_these\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mT:\\Scripts\\occurrence-record-wrangler\\repo_functions.py\u001b[0m in \u001b[0;36mMapShapefilePolygons\u001b[1;34m(map_these, title)\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;31m# Packages needed for plotting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mmpl_toolkits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasemap\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBasemap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpatches\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPolygon\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mpl_toolkits.basemap'"
     ]
    }
   ],
   "source": [
    "gap_range2 = \"{0}{1}_range_4326\".format(inDir, gap_id)\n",
    "\n",
    "shp1 = {'file': gap_range2, 'column': None, 'alias': 'GAP range map',\n",
    "        'drawbounds': False, 'linewidth': .5, 'linecolor': 'y',\n",
    "        'fillcolor': 'y', 'marker':'s'}\n",
    "\n",
    "shp2 = {'file': '{0}{1}_circles'.format(outDir, summary_name), 'column': None,\n",
    "        'alias': 'Occurrence records', 'drawbounds': True, 'linewidth': .75, 'linecolor': 'k',\n",
    "        'fillcolor': None, 'marker':'o'}\n",
    "\n",
    "# Display occurrence polygons\n",
    "if os.path.isfile(gap_range2 + \".shp\"):\n",
    "    map_these=[shp1, shp2]\n",
    "else:\n",
    "    map_these=[shp2]\n",
    "    \n",
    "title=\"{1} ({0})\".format(years, common_name)\n",
    "functions.MapShapefilePolygons(map_these=map_these, title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Years represented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occ_years = [int(x[0]) for x in curs_occ.execute(\"SELECT strftime('%Y', occurrenceDate) FROM occurrences\").fetchall()]\n",
    "years = connjup.execute(\"SELECT years_range FROM gbif_requests WHERE request_id = '{0}'\".format(config.gbif_req_id)).fetchone()[0]\n",
    "years = years.split(',')\n",
    "yearsrng = list(range(int(years[0]), int(years[1]), 1))\n",
    "binsnum = int(years[1]) - int(years[0])\n",
    "plt.hist(occ_years, bins=binsnum)\n",
    "plt.ylabel(\"number of occurrences\")\n",
    "plt.xlabel(\"year\")\n",
    "plt.xticks(yearsrng, rotation=90)\n",
    "plt.title(\"Occurrences per Year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Months represented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occ_months = [int(x[0]) for x in curs_occ.execute(\"SELECT strftime('%m', occurrenceDate) FROM occurrences\").fetchall()]\n",
    "plt.hist(occ_months, bins=range(1, 14), color=\"g\")\n",
    "plt.ylabel(\"number of occurrences\")\n",
    "plt.xlabel(\"month\")\n",
    "plt.xticks(range(1, 13))\n",
    "plt.title(\"Occurrences per Month\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of coordinate uncertainty values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "occ_cert = [int(x[0]) for x in curs_occ.execute(\"SELECT coordinateUncertaintyInMeters FROM occurrences\").fetchall()]\n",
    "maxi = np.max(occ_cert)\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.hist(occ_cert, bins=50, color=\"r\")\n",
    "plt.xticks(range(0, maxi, int(maxi/50)), rotation=90)\n",
    "plt.ylabel(\"number of records\")\n",
    "plt.xlabel(\"coordinate uncertainty\")\n",
    "plt.title(\"Coordinate Uncertainty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_max = 2000\n",
    "occ_cert2 = [x for x in occ_cert if x <= rng_max]\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.hist(occ_cert2, bins=30, color=\"m\", align='mid')\n",
    "plt.xticks(range(0, rng_max + 100, int(rng_max/30.)), rotation=90)\n",
    "plt.ylabel(\"number of records\")\n",
    "plt.xlabel(\"coordinate uncertainty\")\n",
    "plt.title(\"Coordinate Uncertainty\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geodetic datums present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datums = curs_occ.execute(\"SELECT vals FROM record_attributes WHERE field = 'datums' AND step = 'filter';\").fetchone()[0]\n",
    "datums = datums.replace('[', '').strip().replace(']', '').replace(\"'\", \"\")\n",
    "datums = datums.split()\n",
    "for datum in datums:\n",
    "    print(datum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establishment means reported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "establishment = curs_occ.execute(\"SELECT vals FROM record_attributes WHERE field = 'establishment' AND step = 'filter';\").fetchall()[0]\n",
    "for est in establishment:\n",
    "    est = est.replace('[', '').strip().replace(']', '').replace(\"'\", \"\")\n",
    "    print(est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identification qualifiers included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quali = curs_occ.execute(\"SELECT DISTINCT vals FROM record_attributes WHERE field = 'IDqualifier' AND step = 'filter';\").fetchall()[0]\n",
    "for q in quali:\n",
    "    q = q.replace('[', '').strip().replace(']', '').replace(\"'\", \"\")\n",
    "    print(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remarks included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "remarks = curs_occ.execute(\"SELECT DISTINCT remarks FROM occurrences;\").fetchall()\n",
    "#remarks = remarks.replace('[', '').strip().replace(']', '').replace(\"'\", \"\")\n",
    "#remarks = remarks.split(',')\n",
    "if len(remarks) <= 20:\n",
    "    for rem in remarks:\n",
    "        if rem[0][0:1] == ';':\n",
    "            print(rem[0][2:])\n",
    "        else:\n",
    "            print(rem[0])\n",
    "else:\n",
    "    print(\"More than 20 remarks, consult the occurrence database.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = cursorjup.execute(\"SELECT table_name FROM table_descriptions\").fetchall()\n",
    "tables = [x[0] for x in tables]\n",
    "\n",
    "filter_sets = [request_id, filter_id]\n",
    "\n",
    "sources = []\n",
    "for s in filter_sets:\n",
    "    s = s.strip()\n",
    "    for tab in tables:\n",
    "        columns = cursorjup.execute(\"SELECT column_name FROM column_descriptions WHERE table_name = '{0}'\".format(tab)).fetchall()\n",
    "        columns = [x[0] for x in columns]\n",
    "        for col in columns:\n",
    "            try:\n",
    "                a = cursorjup.execute(\"SELECT source FROM {1} WHERE {2} = '{0}'\".format(s, tab, col)).fetchone()[0]\n",
    "                sources.append(a)\n",
    "            except:\n",
    "                pass\n",
    "print(list(set(sources))[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attributes returned for the records in the request (pre-filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fields_summary = pd.read_sql(\"SELECT * FROM gbif_fields_returned\", conn_occ, index_col='index')\n",
    "fields_summary.index.name = 'field'\n",
    "print(fields_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = datetime.now()\n",
    "print(t2 - t1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
